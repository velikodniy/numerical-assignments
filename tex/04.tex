\subsubsection{Задачи линейной алгебры}

Линейная алгебра — это часть математической науки, занимающаяся изучением
векторных (линейных) пространств и их подпространств, линейных отображений,
а также функций на векторных пространствах.

Среди задач линейной алгебры наибольшее значение имеют две:
\begin{itemize}
\item решение систем линейных алгебраических уравнений (СЛАУ),
\item определение собственных значений и собственных векторов матрицы.
\end{itemize}
Другие часто встечающиеся задачи: обращение матрицы, вычисление определителя
и нахождение корней алгебраического многочлена, как правило, не имеют
самостоятельного значения в линейной алгебре и носят вспомогательный
характер при решении основных задач.


\subsubsection{Задача на собственные векторы и собственные значения}

Число $\lambda$ и вектор $\mathbf{x}$ называются соответственно
собственным числом и собственным вектором матрицы $A$, если
\[
A\mathbf{x}=\lambda\mathbf{x}.
\]


То есть, если думать о матрице как о некотром линейном преобразовании
пространства, заключающемся в комбинации поворотов, растяжений и отражений,
то собственный вектор — это вектор, который после такого преобразования
не меняет своего направления, а лишь изменяет длину. Коэффициент изменения
длины (то есть растяжения пространства вдоль вектора) — собственное
значение, соответствующее вектору. Каждому собственному значению соответствует
бесконечно много сонаправленных векторов.

Найдя собственные значения, можно найти и собственные векторы, решая
систему линейных уравнений для каждого из них.

У матрицы может быть несколько собственных значений, но их количество
не превышает $n$.

Различают полную и неполную задачи на собственные значения. В первой
требуется найти все собственные значения, а во второй лишь некоторые
из них.

Необходимость в поиске собственных значений и векторов матрицы часто
возникает, например, в математической физике и теории дифференциальных
и интегральных уравнений.

Рассмотрим определение собственного значения.

\[
A\mathbf{x}=\lambda\mathbf{x},
\]
\[
A\mathbf{x}-\lambda\mathbf{x}=\mathbf{0},
\]
\[
(A-\lambda E)\mathbf{x}=\mathbf{0},
\]
где $E$ — единичная матрица. Матрица, которую представляет выражение
в скобках, определяет некоторую систему линейных уравнений с нулевой
правой частью. Чтобы эта система имела решение, то есть существовали
собственные вкторы, необходимо выполнение равенства
\[
\det(A-\lambda E)=0,
\]
\[
\det\begin{pmatrix}a_{11}-\lambda & a_{12} & \dots & a_{1n}\\
a_{21} & a_{22}-\lambda & \dots & a_{2n}\\
\vdots & \vdots & \ddots & \vdots\\
a_{n1} & a_{n2} & \ldots & a_{nn}-\lambda
\end{pmatrix}=0.
\]


Вычислив определитель, получим алгебраическое уравнение $n$-й степени.
Все собственные значения должны удовлетворять этому уравнению (характеристическому
уравнению матрицы). Однако точное его решения для $n\geqslant5$ в
общем случае невозможно в силу теоремы Абеля—Руффини. Поэтому верна
следующая теорема.
\begin{thm}
Не может существовать прямого метода нахождения собственных значений
произвольной матрицы порядка $n\geqslant5$.
\end{thm}
Для нахождения собственных значений используются различные приближённые
методы, основанные на совйствах собственных значений. Например, степенной
метод или метод вращений (Якоби).


\subsubsection{Прямые методы решения СЛАУ}

Системой линейных алгебраических уравнений называется система уравнений
вида:
\[
\begin{cases}
a_{11}x_{1}+a_{12}x_{2}+\ldots+a_{1n}x_{n} & =b_{1}.\\
a_{21}x_{2}+a_{22}x_{2}+\ldots+a_{2n}x_{n} & =b_{2},\\
\vdots & \vdots\\
a_{n1}x_{1}+a_{n2}x_{2}+\ldots+a_{nn}x_{n} & =b_{n}.
\end{cases}
\]


Удобнее рассматривать её в матричном виде:
\[
A\mathbf{x}=\mathbf{b},
\]
где 
\[
A=\begin{pmatrix}a_{11} & a_{12} & \dots & a_{1n}\\
a_{21} & a_{22} & \dots & a_{2n}\\
\vdots & \vdots & \ddots & \vdots\\
a_{n1} & a_{n2} & \ldots & a_{nn}
\end{pmatrix}.\,\mathbf{x}=\begin{pmatrix}x_{1}\\
x_{2}\\
\vdots\\
x_{n}
\end{pmatrix},\,\mathbf{b}=\begin{pmatrix}b_{1}\\
b_{2}\\
\vdots\\
b_{n}
\end{pmatrix}.
\]


Известно, что эта система имеет единственное решение тогда и только
тогда, когда
\[
\det A\neq0,
\]
то есть матрица $A$ не является вырожденной (сингулярной).

На практике часто встречаются плохо обусловленные (с «почти сингулярной»
матрицей) и переопределённые (уравнений больше, чем неизвестных) системы.
В этом случае применяют регуляризацию — приём, в основе которого лежит
учёт дополнительной информации о структуре решения, которая часто
известна на практике.

Для решения СЛАУ можно использовать прямые методы, которые гарантированно
дадут точный ответ за конечное число шагов. Например, правило Крамера.
Однако, вычисление определителей требует большого объёма вычислений,
поэтому среди прямых методов наиболее распространены методы Гаусса
и Жордана.

Эти методы основаны на следующей идее. Сначала матрица путём сложения
строк и умножения их на константу (эти преобразования не изменяют
решение системы) приводится к треугольному виду:
\[
\begin{pmatrix}a'_{11} & a'_{12} & \dots & a'_{1n}\\
0 & a'_{22} & \dots & a'_{2n}\\
\vdots & \vdots & \ddots & \vdots\\
0 & 0 & \ldots & a'_{nn}
\end{pmatrix}.
\]
Затем начиная с нижней строки поочерёдно находятся корни уравнения.

В методе Гаусса матрица приводится к диагональной последовательно
по столбцам. Сперва обнуляются все элементы, находящиеся под первым
диагональным элементом, затем под вторым и т.д. алгоритм подобного
преобразования выглядит следующим образом.

Пусть дана матрица $B$ размера $n\times(n+1)$, в которой последний
столбец соответствует вектору $\mathbf{b}$.

\framebox{\begin{minipage}[t]{1\columnwidth}%
Для всех $i$ от $1$ до $n-1$:

\qquad{}Для всех $j$ от $i+1$ до $n$:

\qquad{}\qquad{}Для всех $k$ от $i$ до $n+1$:

\qquad{}\qquad{}\qquad{}$B_{jk}\leftarrow B_{jk}-\frac{B_{ik}B_{ji}}{B_{ii}}$%
\end{minipage}}

Этот метод в приведённом виде не всегда корректен, так как диагональный
элемент $B_{ii}$ может оказаться равным нуля. В этом случае нужно
обменять строку $i$ с другой строкой, которая расположена ниже неё
и у которой элемент в столбце $i$ ненулевой (если система имеет единственное
решение, то такая строка должна существовать).

После преобразования матрицы к треугольному виду задача поиска корней
становится тривиальной.

Метод Гаусса имеет кубическую сложность (это следует из трёх вложенных
циклов), то есть время его работы приблизительно пропорционально $n^{3}$.
Это делает его непригодным при работе с матрицами большого размера.


\subsubsection{Методы Якоби и Зейделя}

Прямые методы, хоть и дают точный ответ, вычислительно очень затратны.
Поэтому на практике часто используют итерационные методы, дающие приближённый
результат. Приметром итерационного метода является метод Якоби — аналог
метода последовательных приближений для матричных уравнений.

В самом деле, умножение на матрицу является отображением, преобразующим
исходный вектор в другой, поэтому, если отображение, является сжимающим,
можно воспользоваться теоремой Банаха.

Для того, чтобы применить идею метода последовательных приближений,
нужно преобразовать уравнение к виду
\[
\mathbf{x}=F(\mathbf{x}).
\]


Любую матрицу $A$ можно представить в следующем виде
\[
A=\begin{pmatrix}a_{11} & a_{12} & \dots & a_{1n}\\
a_{21} & a_{22} & \dots & a_{2n}\\
\vdots & \vdots & \ddots & \vdots\\
a_{n1} & a_{n2} & \ldots & a_{nn}
\end{pmatrix}=\begin{pmatrix}0 & 0 & \dots & 0\\
a_{21} & 0 & \dots & 0\\
\vdots & \vdots & \ddots & \vdots\\
a_{n1} & a_{n2} & \ldots & 0
\end{pmatrix}+\begin{pmatrix}a_{11} & 0 & \dots & 0\\
0 & a_{22} & \dots & 0\\
\vdots & \vdots & \ddots & \vdots\\
0 & 0 & \ldots & a_{nn}
\end{pmatrix}+\begin{pmatrix}0 & a_{12} & \dots & a_{1n}\\
0 & 0 & \dots & a_{2n}\\
\vdots & \vdots & \ddots & \vdots\\
0 & 0 & \ldots & 0
\end{pmatrix}.
\]
То есть, матрица равна сумме поддиагональной, диагональной и наддиагональной
матриц. После переобозначения
\[
A=L+D+R.
\]


Тогда исходное уравнение принимает вид
\[
A\mathbf{x}=\mathbf{b},
\]
\[
D\mathbf{x}=-(L+R)\mathbf{x}+\mathbf{b},
\]
\[
\mathbf{x}=-D^{-1}\left((L+R)\mathbf{x}-\mathbf{b}\right).
\]


Здесь $D^{-1}$ — обратная матрица. Вообще говоря, вычисление обратной
матрицы является задачей столь же сложной, как и решение системы линейных
уравнений, но в данном случае можно воспользоваться тем, что $D$
— диагональная. Для неё обратная матрица имеет вид
\[
D^{-1}=\begin{pmatrix}a_{11} & 0 & \dots & 0\\
0 & a_{22} & \dots & 0\\
\vdots & \vdots & \ddots & \vdots\\
0 & 0 & \ldots & a_{nn}
\end{pmatrix}^{-1}=\begin{pmatrix}\frac{1}{a_{11}} & 0 & \dots & 0\\
0 & \frac{1}{a_{22}} & \dots & 0\\
\vdots & \vdots & \ddots & \vdots\\
0 & 0 & \ldots & \frac{1}{a_{nn}}
\end{pmatrix}.
\]


Таким образом, получаем следующее отображение
\[
F(\mathbf{x})=-D^{-1}\left((L+R)\mathbf{x}-\mathbf{b}\right).
\]


Можно составить алгоритм решения на основе метода последовательных
приближений.
\begin{enumerate}
\item Выбирается произвольный вектор $\mathbf{x}_{0}$.
\item На основе текущего приближения вычисляется следующее
\[
\mathbf{x}^{k+1}=F(\mathbf{x}^{k}).
\]

\item Если не достигнута достаточная точность, что проверяется, например,
условием
\[
\|\mathbf{x}^{k+1}-\mathbf{x}^{k}\|\geqslant\varepsilon,
\]
возвращаемся к п. 2.
\end{enumerate}
В качестве нормы можно использовать, например, нормы пространств $\mathbb{R}^{n}$
или $l_{n}$.

Однако, для сходимости требуется, чтобы отображение $F$ было сжимающим.
\begin{thm}[Достаточное условие сходимости]
В случае диагонального преобладания элементов матрицы $A$ ($a_{ii}>\sum_{j\neq i}a_{ij}$.
$i=1,2,\ldots,n$) метод Якоби сходится к решению задачи
\[
A\mathbf{x}=\mathbf{b}
\]
при любом начальном приближении $\mathbf{x}_{0}$.
\end{thm}

\begin{thm}[Необходимое и достаточное условие сходимости]
Метод Якоби сходится к решению тогда и только тогда, когда все корни
уравнения \textup{
\[
\begin{vmatrix}\lambda a_{11} & a_{12} & \ldots & a_{1n}\\
a_{21} & \lambda a_{22} & \ldots & a_{2n}\\
\vdots & \vdots & \ddots & \vdots\\
a_{n1} & a_{n2} & \ldots & \lambda a_{nn}
\end{vmatrix}=0
\]
}по модулю меньше 1.
\end{thm}
Одну итерацию метода Якоби можно записать в виде
\begin{eqnarray*}
x_{1}^{k+1} & = & \frac{1}{a_{11}}\left(b_{1}-a_{12}x_{2}^{k}-a_{13}x_{3}^{k}-\ldots-a_{1n}x_{n}^{k}\right),\\
x_{2}^{k+1} & = & \frac{1}{a_{22}}\left(b_{2}-a_{21}x_{1}^{k}-a_{23}x_{3}^{k}-\ldots-a_{2n}x_{n}^{k}\right),\\
 & \vdots\\
x_{n}^{k+1} & = & \frac{1}{a_{nn}}\left(b_{n}-a_{n1}x_{1}^{k}-a_{n2}x_{2}^{k}-\ldots-a_{n,n-1}x_{n-1}^{k}\right).
\end{eqnarray*}


В методе Якоби для получения всех компонент вектора $\mathbf{x}^{k+1}$
используются компоненты $k$-го приближения. Идея метода Зейделя заключается
в том, что при вычислении $i$-й компоненты $\mathbf{x}_{i}^{k+1}$
используются уже вычисленные $1,2,\ldots,i-1$ компоненты. Получаем
слудующие выражения:
\begin{eqnarray*}
x_{1}^{k+1} & = & \frac{1}{a_{11}}\left(b_{1}-a_{12}x_{2}^{k}-a_{13}x_{3}^{k}-\ldots-a_{1n}x_{n}^{k}\right),\\
x_{2}^{k+1} & = & \frac{1}{a_{22}}\left(b_{2}-a_{21}x_{1}^{k+1}-a_{23}x_{3}^{k}-\ldots-a_{2n}x_{n}^{k}\right),\\
x_{3}^{k+1} & = & \frac{1}{a_{33}}\left(b_{3}-a_{31}x_{1}^{k+1}-a_{32}x_{3}^{k+1}-a_{34}x_{4}^{k}\ldots-a_{3n}x_{n}^{k}\right),\\
 & \vdots\\
x_{n}^{k+1} & = & \frac{1}{a_{nn}}\left(b_{n}-a_{n1}x_{1}^{k+1}-a_{n2}x_{2}^{k+1}-\ldots-a_{n,n-1}x_{n-1}^{k+1}\right).
\end{eqnarray*}

\begin{thm}
Метод Зейделя сходится к решению тогда и только тогда, когда все корни
уравнения \textup{
\[
\begin{vmatrix}\lambda a_{11} & a_{12} & \ldots & a_{1n}\\
\lambda a_{21} & \lambda a_{22} & \ldots & a_{2n}\\
\vdots & \vdots & \ddots & \vdots\\
\lambda a_{n1} & \lambda a_{n2} & \ldots & \lambda a_{nn}
\end{vmatrix}=0
\]
}по модулю меньше 1.
\end{thm}
Задача:

Необходимо запрограммировать и исследовать следующие методы:

метод Гаусса (метод Гаусса без выбора главного элемента); метод Якоби;
метод Зейделя.

При желании можно также реализовать:

метод Ньютона для систем уравнений.

В результатах должно быть представлено:

исходные задачи (матрица и вектор свободных членов); точные решения;
решения задач, полученные каждым их методов.

В заключительной части нужно сделать выводы, дающие ответ на следующие
вопросы:

Какой из методов наиболее точный? Какой метод самый быстрый? (Необходимо
провести измерение скорости выполнения.) Потребовалось ли преобразовывать
систему для использования метода? В каких ситуациях это требуется
делать?

